# ctransformers[cuda]
# huggingface_hub

# huggingface_hub>=0.16.4
# uvicorn==0.24.0.post1

# pyarrow==14.0.2
# pandas==2.1.4
# ray==2.9.0

# vllm==0.2.7
# torch>=2.1.0
# exllamav2==0.0.11

# pydantic<2.0,>=1.7.4,!=1.8,!=1.8.1


huggingface-hub==0.20.2

pyarrow==14.0.2
pandas==2.1.4

ninja
psutil
ray >= 2.5.1
sentencepiece  # Required for LLaMA tokenizer.
numpy
torch == 2.1.2
transformers >= 4.36.0  # Required for Mixtral.
xformers == 0.0.23.post1  # Required for CUDA 12.1.
fastapi
uvicorn[standard]
pydantic >= 2.0  # Required for OpenAI server.
aioprometheus[starlette]

vllm==0.3.0
httpx